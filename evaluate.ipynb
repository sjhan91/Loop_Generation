{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import jupyter_black\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.metrics import *\n",
    "\n",
    "from prdc import compute_prdc\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from loop_extraction.src.BERT import BERT_Lightning\n",
    "from loop_extraction.src.utils.utils import dataset_split\n",
    "from loop_extraction.src.utils.utils import folder_to_multiple_file\n",
    "\n",
    "from loop_extraction.src.utils.remi import *\n",
    "from loop_extraction.src.utils.vocab import *\n",
    "from loop_extraction.src.utils.constants import *\n",
    "from loop_extraction.src.utils.bpe_encode import MusicTokenizer\n",
    "\n",
    "jupyter_black.load(line_length=100)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bins(KEY):\n",
    "    bins = None\n",
    "\n",
    "    if KEY == TEMPO_KEY:\n",
    "        bins = DEFAULT_TEMPO_BINS\n",
    "    elif KEY == VELOCITY_KEY:\n",
    "        bins = DEFAULT_VELOCITY_BINS\n",
    "    elif KEY == DURATION_KEY:\n",
    "        bins = DEFAULT_DURATION_BINS\n",
    "\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_value(tokens, KEY):\n",
    "    indices = [int(token.split(\"_\")[-1]) for token in tokens if KEY in token]\n",
    "\n",
    "    if KEY == PITCH_KEY:\n",
    "        return np.mean(indices)\n",
    "\n",
    "    bins = get_bins(KEY)\n",
    "    return np.mean([bins[index] for index in indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controllability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/workspace/loop_generation/samples/GPT-medium_random_drop_0-cond_full\"\n",
    "test_files = glob.glob(os.path.join(path, \"*\"))\n",
    "\n",
    "results = []\n",
    "for i, file_path in enumerate(test_files):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        x = pickle.load(f)\n",
    "\n",
    "    # 1. instrument - Jaccard iimilarity\n",
    "    pred_inst = list(set([token for token in x[\"loop\"] if INSTRUMENT_KEY in token]))\n",
    "    true_inst = x[\"inst\"]\n",
    "\n",
    "    nom = len(set(pred_inst).intersection(set(true_inst)))\n",
    "    denom = len(set(pred_inst).union(set(true_inst)))\n",
    "    inst = nom / denom\n",
    "\n",
    "    # 2. mean_family\n",
    "    pred_results = []\n",
    "    for key in [PITCH_KEY, TEMPO_KEY, VELOCITY_KEY, DURATION_KEY]:\n",
    "        value = get_mean_value(x[\"loop\"], key)\n",
    "        pred_results.append(value)\n",
    "\n",
    "    true_results = []\n",
    "    for token in [x[\"mean_pitch\"], x[\"mean_tempo\"], x[\"mean_velocity\"], x[\"mean_duration\"]]:\n",
    "        key, index = token[0].split(\"_\")\n",
    "        bins = get_bins(key)\n",
    "\n",
    "        if bins is not None:\n",
    "            true_results.append(bins[int(index)])\n",
    "        else:\n",
    "            true_results.append(int(index))\n",
    "\n",
    "    # distance\n",
    "    pred_results = np.array(pred_results)\n",
    "    true_results = np.array(true_results)\n",
    "    mean_family = np.abs(pred_results - true_results).tolist()\n",
    "\n",
    "    # 3. bar_length\n",
    "    pred_length = len(list([token for token in x[\"loop\"] if BAR_KEY in token]))\n",
    "    true_length = int(x[\"bar_length\"][0].split(\"_\")[-1])\n",
    "    bar_length = 1 if pred_length == true_length else 0\n",
    "\n",
    "    results.append([inst] + mean_family + [bar_length])\n",
    "\n",
    "print(f\"Results : {np.mean(np.array(results), axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load BERT-stranger model\n",
    "with open(\"./loop_extraction/config/config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# initialize model with GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(0 if use_cuda else \"cpu\")\n",
    "\n",
    "# tokenizer path\n",
    "bpe_path = \"./loop_extraction/tokenizer/tokenizer.json\"\n",
    "bpe_meta_path = \"./loop_extraction/tokenizer/tokenizer_meta.json\"\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = MusicTokenizer(bpe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load datasets\n",
    "folder_path = \"./data/\"\n",
    "datasets = [\"lmd_full_loop_1024\", \"meta_midi_loop_1024\"]\n",
    "\n",
    "folder_list = []\n",
    "for dataset in datasets:\n",
    "    folder_list += glob.glob(os.path.join(folder_path, dataset, \"*\"))\n",
    "\n",
    "random.shuffle(folder_list)\n",
    "\n",
    "#### split song into train, val, test\n",
    "train_folder, val_folder, test_folder = dataset_split(folder_list, train_ratio=0.98, val_ratio=0.01)\n",
    "\n",
    "#### get file_path of each dataset\n",
    "train_files = folder_to_multiple_file(train_folder, k=1)\n",
    "train_files = train_files[: len(test_files)]\n",
    "\n",
    "print(f\"train_files : {len(train_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = BERT_Lightning(\n",
    "    dim=config[\"dim\"],\n",
    "    depth=config[\"depth\"],\n",
    "    heads=config[\"heads\"],\n",
    "    dim_head=int(config[\"dim\"] / config[\"heads\"]),\n",
    "    mlp_dim=int(4 * config[\"dim\"]),\n",
    "    max_len=config[\"max_len\"],\n",
    "    rate=config[\"rate\"],\n",
    "    bpe_path=bpe_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(\n",
    "    \"./loop_extraction//model/BERT-stranger.ckpt\",\n",
    "    dim=config[\"dim\"],\n",
    "    depth=config[\"depth\"],\n",
    "    heads=config[\"heads\"],\n",
    "    dim_head=int(config[\"dim\"] / config[\"heads\"]),\n",
    "    mlp_dim=int(4 * config[\"dim\"]),\n",
    "    max_len=config[\"max_len\"],\n",
    "    rate=config[\"rate\"],\n",
    "    bpe_path=bpe_path,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat(files):\n",
    "    results = []\n",
    "\n",
    "    for i, file_path in enumerate(files):\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            events = pickle.load(f)[\"loop\"]\n",
    "\n",
    "        bars = [i for i, event in enumerate(events) if f\"{BAR_KEY}_\" in event]\n",
    "\n",
    "        contexts = list(zip(bars[:-1], bars[1:])) + [(bars[-1], len(events))]\n",
    "        contexts = [\n",
    "            (start, end)\n",
    "            if (end - start) <= (MAX_TOKEN_LEN - 1)\n",
    "            else (start, start + (MAX_TOKEN_LEN - 1))\n",
    "            for (start, end) in contexts\n",
    "        ]\n",
    "\n",
    "        music = []\n",
    "        for j, (start, end) in enumerate(contexts):\n",
    "            bar = events[start:end]\n",
    "\n",
    "            if EOB_TOKEN not in bar:\n",
    "                bar = bar + [EOB_TOKEN]\n",
    "\n",
    "            # REMI to BPE tokens\n",
    "            bar = tokenizer.encode(bar)\n",
    "            bar = torch.tensor(bar, dtype=torch.long).to(device)\n",
    "            music.append(bar)\n",
    "\n",
    "        pad_idx = RemiVocab().to_i(PAD_TOKEN)\n",
    "        music = pad_sequence(music, batch_first=True, padding_value=pad_idx)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, h = model(music)\n",
    "\n",
    "        results.append(h.detach().cpu().numpy())\n",
    "\n",
    "    return np.vstack(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features\n",
    "train_feat = get_feat(train_files)\n",
    "gen_feat = get_feat(test_files)\n",
    "\n",
    "print(f\"train_feat : {len(train_feat)}, gen_feat : {len(gen_feat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get precision & recall & density & coverage\n",
    "metrics = compute_prdc(real_features=train_feat, fake_features=gen_feat, nearest_k=5)\n",
    "print(f\"prdc : {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get FID\n",
    "fid = compute_fid(train_feat, gen_feat)\n",
    "print(f\"fid : {fid}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
